{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_3NNVJUXYoUYSLk6n2t1KZX9eQzXT7EC",
      "authorship_tag": "ABX9TyMl8IBz9iY+w81AioY2A5Kq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamJ70/BYOP/blob/main/umeed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itrp2-L0H7y4",
        "outputId": "ea94153e-721a-4a72-a4dc-2f0f1a9d99c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchaudio) (3.0.2)\n",
            "Collecting phonemizer\n",
            "  Downloading phonemizer-3.3.0-py3-none-any.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from phonemizer) (1.4.2)\n",
            "Collecting segments (from phonemizer)\n",
            "  Downloading segments-2.2.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: attrs>=18.1 in /usr/local/lib/python3.10/dist-packages (from phonemizer) (24.2.0)\n",
            "Collecting dlinfo (from phonemizer)\n",
            "  Downloading dlinfo-1.2.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from phonemizer) (4.12.2)\n",
            "Collecting clldutils>=1.7.3 (from segments->phonemizer)\n",
            "  Downloading clldutils-3.24.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting csvw>=1.5.6 (from segments->phonemizer)\n",
            "  Downloading csvw-3.5.1-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from segments->phonemizer) (2024.9.11)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer) (2.8.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer) (0.9.0)\n",
            "Collecting colorlog (from clldutils>=1.7.3->segments->phonemizer)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting bibtexparser>=2.0.0b4 (from clldutils>=1.7.3->segments->phonemizer)\n",
            "  Downloading bibtexparser-2.0.0b8-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pylatexenc (from clldutils>=1.7.3->segments->phonemizer)\n",
            "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer) (3.7)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer) (5.3.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer) (3.0.2)\n",
            "Collecting isodate (from csvw>=1.5.6->segments->phonemizer)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting rfc3986<2 (from csvw>=1.5.6->segments->phonemizer)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: uritemplate>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer) (4.1.1)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer) (2.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer) (2.32.3)\n",
            "Collecting language-tags (from csvw>=1.5.6->segments->phonemizer)\n",
            "  Downloading language_tags-1.2.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting rdflib (from csvw>=1.5.6->segments->phonemizer)\n",
            "  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting colorama (from csvw>=1.5.6->segments->phonemizer)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer) (4.23.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.22.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->clldutils>=1.7.3->segments->phonemizer) (1.16.0)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib->csvw>=1.5.6->segments->phonemizer) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer) (2024.8.30)\n",
            "Downloading phonemizer-3.3.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.8/103.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading dlinfo-1.2.1-py3-none-any.whl (3.6 kB)\n",
            "Downloading segments-2.2.1-py2.py3-none-any.whl (15 kB)\n",
            "Downloading clldutils-3.24.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading csvw-3.5.1-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bibtexparser-2.0.0b8-py3-none-any.whl (39 kB)\n",
            "Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading language_tags-1.2.0-py3-none-any.whl (213 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.4/213.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rdflib-7.1.1-py3-none-any.whl (562 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pylatexenc\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136816 sha256=1bce68efd71cc010d9b96299027535e60e57d59a91164548034a9a0607dbb034\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/31/8b/e09b0386afd80cfc556c00408c9aeea5c35c4d484a9c762fd5\n",
            "Successfully built pylatexenc\n",
            "Installing collected packages: rfc3986, pylatexenc, pydub, language-tags, dlinfo, isodate, colorlog, colorama, bibtexparser, rdflib, clldutils, csvw, segments, phonemizer\n",
            "Successfully installed bibtexparser-2.0.0b8 clldutils-3.24.0 colorama-0.4.6 colorlog-6.9.0 csvw-3.5.1 dlinfo-1.2.1 isodate-0.7.2 language-tags-1.2.0 phonemizer-3.3.0 pydub-0.25.1 pylatexenc-2.10 rdflib-7.1.1 rfc3986-1.5.0 segments-2.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torchaudio transformers librosa tqdm numpy\n",
        "!pip install phonemizer pydub\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from phonemizer import phonemize\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "# Paths\n",
        "dataset_path = \"/content/drive/MyDrive/nus-smc-corpus_48\"\n",
        "output_path = \"/content/drive/MyDrive\"\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# Helper functions\n",
        "def preprocess_audio(audio_file):\n",
        "    \"\"\"Convert audio to Mel-spectrogram.\"\"\"\n",
        "    waveform, sr = librosa.load(audio_file, sr=22050)\n",
        "    mel_spec = librosa.feature.melspectrogram(\n",
        "        y=waveform, sr=sr, n_fft=2048, hop_length=512, n_mels=80\n",
        "    )\n",
        "    log_mel_spec = librosa.power_to_db(mel_spec)\n",
        "    return log_mel_spec\n",
        "\n",
        "def preprocess_annotations(annotation_file):\n",
        "    \"\"\"Read time-aligned annotations and convert them to phonemes.\"\"\"\n",
        "    with open(annotation_file, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "    phonemes = \" \".join([line.split()[2] for line in lines])  # Extract phoneme column\n",
        "    return phonemes\n",
        "\n",
        "# Process dataset\n",
        "data = []\n",
        "subjects = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
        "\n",
        "for subject in tqdm(subjects):\n",
        "    subject_path = os.path.join(dataset_path, subject)\n",
        "    sing_folder = os.path.join(subject_path, \"sing\")\n",
        "\n",
        "    if not os.path.exists(sing_folder):\n",
        "        print(f\"Skipping {subject}: 'sing' folder not found.\")\n",
        "        continue\n",
        "\n",
        "    for audio_file in os.listdir(sing_folder):\n",
        "        if audio_file.endswith(\".wav\"):\n",
        "            audio_file_path = os.path.join(sing_folder, audio_file)\n",
        "            annotation_file_path = os.path.join(sing_folder, audio_file.replace(\".wav\", \".txt\"))\n",
        "\n",
        "            if not os.path.exists(annotation_file_path):\n",
        "                print(f\"Skipping {audio_file}: No corresponding annotation file.\")\n",
        "                continue\n",
        "\n",
        "            # Preprocess audio and annotations\n",
        "            mel_spec = preprocess_audio(audio_file_path)\n",
        "            phonemes = preprocess_annotations(annotation_file_path)\n",
        "\n",
        "            # Append processed data\n",
        "            data.append((mel_spec, phonemes))\n",
        "\n",
        "# Save processed data\n",
        "output_file = os.path.join(output_path, \"preprocessed_data.pkl\")\n",
        "with open(output_file, \"wb\") as f:\n",
        "    pickle.dump(data, f)\n",
        "\n",
        "print(f\"Preprocessing complete! Data saved at {output_file}.\")"
      ],
      "metadata": {
        "id": "gZID_7BzenK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "class MelodyDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        mel_spectrogram, phonemes = self.data[idx]\n",
        "        phonemes = str(phonemes)  # Ensure phonemes are strings\n",
        "        mel_spectrogram = np.array(mel_spectrogram, dtype=np.float32)\n",
        "        return phonemes, torch.tensor(mel_spectrogram)\n",
        "\n",
        "# Pad variable-length tensors in a batch\n",
        "def collate_fn(batch):\n",
        "    phonemes, mel_spectrograms = zip(*batch)\n",
        "    max_time = max(mel.shape[1] for mel in mel_spectrograms)\n",
        "    padded_mel_spectrograms = torch.stack([\n",
        "        torch.nn.functional.pad(\n",
        "            mel, (0, max_time - mel.shape[1]), mode=\"constant\", value=0\n",
        "        )\n",
        "        for mel in mel_spectrograms\n",
        "    ])\n",
        "    return list(phonemes), padded_mel_spectrograms\n",
        "\n",
        "# Load preprocessed data\n",
        "with open(\"/content/drive/MyDrive/preprocessed_data.pkl\", \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "# Create Dataset and DataLoader with padding\n",
        "dataset = MelodyDataset(data)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
        "# Create Dataset and DataLoader with padding\n",
        "dataset = MelodyDataset(data)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
        "# Load preprocessed data\n",
        "# with open(\"/content/drive/MyDrive/preprocessed_data.pkl\", \"rb\") as f:\n",
        "#     data = pickle.load(f)\n",
        "\n",
        "# # Assume the dataset is a list of (phonemes, mel_spectrogram) pairs\n",
        "# from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# class MelodyDataset(Dataset):\n",
        "#     def __init__(self, data):\n",
        "#         self.data = data\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         phonemes, mel_spectrogram = self.data[idx]\n",
        "#         return phonemes, mel_spectrogram\n",
        "\n",
        "# dataset = MelodyDataset(data)\n",
        "# dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n"
      ],
      "metadata": {
        "id": "QxM4LqEPH_b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from transformers import MBartForConditionalGeneration, MBartTokenizer\n",
        "\n",
        "# Load MBart model and tokenizer\n",
        "model_name = \"facebook/mbart-large-cc25\"\n",
        "tokenizer = MBartTokenizer.from_pretrained(model_name)\n",
        "text_to_melody_model = MBartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Define the TacotronWrapper for text-to-melody generation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-y8YBn_K5Oh",
        "outputId": "089cc874-710a-4d91-9264-3507be70bae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TacotronWrapper(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TacotronWrapper, self).__init__()\n",
        "        self.text_to_melody = text_to_melody_model\n",
        "\n",
        "    def forward(self, phonemes):\n",
        "        if not isinstance(phonemes, list):  # Ensure phonemes are a list of strings\n",
        "            raise ValueError(\"Phonemes must be a list of strings.\")\n",
        "\n",
        "    # Tokenize input text\n",
        "        tokens = tokenizer(phonemes, return_tensors=\"pt\", padding=True, truncation=True).to(next(self.text_to_melody.parameters()).device)\n",
        "        tokens['input_ids'] = tokens['input_ids'].to(torch.int64)\n",
        "    # Debug: Check indices\n",
        "        max_index = tokens['input_ids'].max()\n",
        "        if max_index >= tokenizer.vocab_size:\n",
        "            raise ValueError(f\"Token index out of range: {max_index} exceeds vocab size {tokenizer.vocab_size}\")\n",
        "\n",
        "    # Clamp to avoid index issues\n",
        "        tokens['input_ids'] = torch.clamp(tokens['input_ids'], max=tokenizer.vocab_size - 1)\n",
        "\n",
        "    # Forward pass through the model\n",
        "        outputs = self.text_to_melody(**tokens)\n",
        "        mel_spectrogram = outputs.logits\n",
        "\n",
        "    # Truncate sequence length (optional, for large outputs)\n",
        "        max_time_steps = 8000  # Define max time steps\n",
        "        if mel_spectrogram.shape[2] > max_time_steps:\n",
        "            mel_spectrogram = mel_spectrogram[:, :, :max_time_steps]\n",
        "\n",
        "        return mel_spectrogram\n"
      ],
      "metadata": {
        "id": "jJQX_aWqwAQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "def griffinlim(mel_spectrogram, sr, iterations=50):\n",
        "    # This function takes the magnitude spectrogram and performs the Griffin-Lim inversion\n",
        "    # mel_spectrogram: Input magnitude spectrogram\n",
        "    # sr: Sample rate\n",
        "    # iterations: Number of iterations for Griffin-Lim algorithm\n",
        "    angle_spectrogram = np.angle(np.exp(2j * np.pi * np.random.uniform(0, 1, mel_spectrogram.shape)))\n",
        "    reconstructed = librosa.istft(mel_spectrogram * np.exp(1j * angle_spectrogram), hop_length=256, win_length=1024)\n",
        "    for _ in range(iterations):\n",
        "        angles = np.angle(librosa.stft(reconstructed, hop_length=256, win_length=1024))\n",
        "        reconstructed = librosa.istft(mel_spectrogram * np.exp(1j * angles), hop_length=256, win_length=1024)\n",
        "    return reconstructed\n",
        "\n",
        "def generate_audio_from_mel(mel_spectrogram, output_path=\"output.wav\"):\n",
        "    audio = griffinlim(mel_spectrogram.T, 22050)  # Transpose for the Griffin-Lim function\n",
        "    sf.write(output_path, audio, samplerate=22050)\n",
        "    print(f\"Generated audio saved at {output_path}\")"
      ],
      "metadata": {
        "id": "uQLp0Pu-K-8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import accumulate\n",
        "from tqdm import tqdm\n",
        "tacotron_model = TacotronWrapper()\n",
        "optimizer = torch.optim.Adam(tacotron_model.parameters(), lr=1e-4)\n",
        "# Import necessary libraries\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "\n",
        "accumulation_steps = 4  # Number of steps to accumulate gradients before updating weights\n",
        "# Define custom loss: STFT Loss (Optional but recommended)\n",
        "def stft_loss(pred, target):\n",
        "    pred=pred.mean(dim=1)\n",
        "    target=target.mean(dim=1)\n",
        "    pred_stft = torch.stft(pred.squeeze(1), n_fft=1024, hop_length=256, win_length=1024, return_complex=False)\n",
        "    target_stft = torch.stft(target.squeeze(1), n_fft=1024, hop_length=256, win_length=1024, return_complex=False)\n",
        "    return F.l1_loss(pred_stft, target_stft)\n",
        "\n",
        "# Initialize AMP GradScaler\n",
        "scaler = torch.amp.GradScaler()  # Updated per deprecation warning\n",
        "\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10):  # Adjust epochs as needed\n",
        "    epoch_loss = 0\n",
        "    tacotron_model.train()\n",
        "\n",
        "    for step, (phonemes, mel_spec) in enumerate(tqdm(dataloader)):\n",
        "        print(max(phonemes), min(phonemes))\n",
        "        print(f\"Phonemes indices: {phonemes}\")\n",
        "        print(f\"Mel Spec indices: {mel_spec}\")\n",
        "        optimizer.zero_grad()\n",
        "            # Forward pass\n",
        "        generated_mel = tacotron_model(phonemes)\n",
        "\n",
        "            # Project generated mel to match target mel dimensions\n",
        "        if generated_mel.size(1) != 80:  # Check if projection is needed\n",
        "            projection_layer = torch.nn.Linear(generated_mel.size(1), 80).to(generated_mel.device)\n",
        "            projected_mel = projection_layer(generated_mel.transpose(1, 2)).transpose(1, 2)\n",
        "        else:\n",
        "            projected_mel = generated_mel  # No projection needed if already 80 channels\n",
        "\n",
        "            # Align sequence length\n",
        "        if projected_mel.shape[2] > mel_spec.shape[2]:  # Trim\n",
        "                projected_mel = projected_mel[:, :, :mel_spec.shape[2]]\n",
        "        elif projected_mel.shape[2] < mel_spec.shape[2]:  # Pad\n",
        "                padding = mel_spec.shape[2] - projected_mel.shape[2]\n",
        "                projected_mel = F.pad(projected_mel, (0, padding))\n",
        "\n",
        "            # Compute loss (Use L1 loss or STFT loss)\n",
        "        loss = stft_loss(projected_mel, mel_spec) / accumulation_steps\n",
        "\n",
        "        scaler.scale(loss).backward()  # Scaled loss for AMP\n",
        "        if (step + 1) % accumulation_steps == 0 or (step + 1) == len(dataloader):\n",
        "          scaler.step(optimizer)\n",
        "          scaler.update()\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / len(dataloader)}\")\n",
        "\n",
        "def generate_audio_from_mel(mel_spectrogram, output_path=\"output.wav\"):\n",
        "    audio = griffinlim(mel_spectrogram.T, 22050)\n",
        "    sf.write(output_path, audio, samplerate=22050)\n",
        "    print(f\"Generated audio saved at {output_path}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-ZaKzsvLQLY",
        "outputId": "ab371d49-2974-4a43-faa1-8ec72ca277b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n",
            "  0%|          | 0/48 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sil t w ih ng k ah sp t w ih ng k ah sp l ih t ow sp s t aa r sp hh aw sp ay sp w ah n d er sp w ah n sil y uw w sp aa r sil ah b sp ah b ah v sp dh ah sp w er ah d sp s ow sp hh ay sil l ay k sp ah sp d ay m eh n d sp ih n sp ah sp s k ay sil t w ih ng k ow sp t w ih ng k ah sp l ih t ow sp s t aa r sil hh aw sp ay sp w ao ah n d er sp w ah sil y uw w sp aa r sil w ah n sp ah sp b l ey z ih ng sp s aa n sp ih s sp g ao n sil w eh n sp hh iy sp n ah th ih ng sp sh ay n s sp ah p ao n sil dh eh n sp y ah sp sh ow sp y ao sp l ih t ow sp l ay t sil t w ah ng k ow sp t w ih ng k ow l sp ao sp dh ah sp n ay t sil t w ih ng k ah sp t w ih ng k ah sp l ih t ow sp s t aa r sil hh aw sp ay sp w ah n d er sp w ah sil y uw w sp aa r sil dh eh n sp ah sp ch r aa v l er sil ih n sp ah sp d aa r k sil th ey ng k s sp y uw sp f uw oy sp y ah r sp t ay n iy sp s p ao sil hh iy sp k uh sp n ao sp s iy sp w ih ch sp w ey sp t uw sp g ow sil ih f sp y uw sp d ih sp n aa sp t w ih n k ow sp s ow sil t w ih ng k ow sp t w ih ng k ah sp l ih t ow sp s dh ao r sil hh aw sp ay sp w ao ah n d er sp w ah sil y uw w sp aa r sil ih n sp ah sp d aa n sil b l uw sp s k ay sp y uw sp k iy p sp eh n d sil ao f eh n sp dh r uw sp m ay sp k ah er n s sp p iy p sil f ao ay sp y ah sp n eh v er sp sh ah sil y ao er sil ay sil t ah ao sp dh ah sp s aa n sp ih z sp ih n sp ah sp s k ay sil t w ih ng k ah sp t w ih ng k ow sp l ih t ow sp s t aa r sil hh aw sp ay sp w ao ah n d er sp w ah sil y uw w sp aa r sil ae s sp y uh er sp b r ay t sp eh n sp t ay n iy sp s p aa r k sil l ay s sp dh ah sp ch r ah v l ah r sp ih n sp ah sp d aa r k sil dh aw w sp ay sp n ow sp n aa t sp w ah sil y uw w sp aa r sil t w ih ng k ah sp t w ih ng k ow sp l ih t ow sp s t aa r sil t w ih ng k ah l sp t w ih ng k ah sp l ih t ow sp s t aa r sil hh aw sp ay sp w ao ah n d er sp w ah sp y uw w sp aa r sil ah p sp ah b ah f sp dh ah sp w er ah sp s ow sp hh ay sil l ay k sp ah sp d ay m ah n d sp ih n sp ah sp s k ay sil t w ih ng k ow sp t w ih ng k ah sp l ih t ow sp s t ao r sil hh aw sp ay sp w ah n d er sp w ao ah sil y uw w sp aa r sil hh aw sp ay sp w ao ah n d er sp w ah sil y uw w sp aa r sil sil t w ih ng k ah sp t w ih ng k ah sp l ih t ow sp s t aa r sp hh aw sp ay sp w ah n d er sp w ah n sil y uw w sp aa r sil ah b sp ah b ah v sp dh ah sp w er ah d sp s ow sp hh ay sil l ay k sp ah sp d ay m eh n d sp ih n sp ah sp s k ay sil t w ih ng k ow sp t w ih ng k ah sp l ih t ow sp s t aa r sil hh aw sp ay sp w ao ah n d er sp w ah sil y uw w sp aa r sil w ah n sp ah sp b l ey z ih ng sp s aa n sp ih s sp g ao n sil w eh n sp hh iy sp n ah th ih ng sp sh ay n s sp ah p ao n sil dh eh n sp y ah sp sh ow sp y ao sp l ih t ow sp l ay t sil t w ah ng k ow sp t w ih ng k ow l sp ao sp dh ah sp n ay t sil t w ih ng k ah sp t w ih ng k ah sp l ih t ow sp s t aa r sil hh aw sp ay sp w ah n d er sp w ah sil y uw w sp aa r sil dh eh n sp ah sp ch r aa v l er sil ih n sp ah sp d aa r k sil th ey ng k s sp y uw sp f uw oy sp y ah r sp t ay n iy sp s p ao sil hh iy sp k uh sp n ao sp s iy sp w ih ch sp w ey sp t uw sp g ow sil ih f sp y uw sp d ih sp n aa sp t w ih n k ow sp s ow sil t w ih ng k ow sp t w ih ng k ah sp l ih t ow sp s dh ao r sil hh aw sp ay sp w ao ah n d er sp w ah sil y uw w sp aa r sil ih n sp ah sp d aa n sil b l uw sp s k ay sp y uw sp k iy p sp eh n d sil ao f eh n sp dh r uw sp m ay sp k ah er n s sp p iy p sil f ao ay sp y ah sp n eh v er sp sh ah sil y ao er sil ay sil t ah ao sp dh ah sp s aa n sp ih z sp ih n sp ah sp s k ay sil t w ih ng k ah sp t w ih ng k ow sp l ih t ow sp s t aa r sil hh aw sp ay sp w ao ah n d er sp w ah sil y uw w sp aa r sil ae s sp y uh er sp b r ay t sp eh n sp t ay n iy sp s p aa r k sil l ay s sp dh ah sp ch r ah v l ah r sp ih n sp ah sp d aa r k sil dh aw w sp ay sp n ow sp n aa t sp w ah sil y uw w sp aa r sil t w ih ng k ah sp t w ih ng k ow sp l ih t ow sp s t aa r sil t w ih ng k ah l sp t w ih ng k ah sp l ih t ow sp s t aa r sil hh aw sp ay sp w ao ah n d er sp w ah sp y uw w sp aa r sil ah p sp ah b ah f sp dh ah sp w er ah sp s ow sp hh ay sil l ay k sp ah sp d ay m ah n d sp ih n sp ah sp s k ay sil t w ih ng k ow sp t w ih ng k ah sp l ih t ow sp s t ao r sil hh aw sp ay sp w ah n d er sp w ao ah sil y uw w sp aa r sil hh aw sp ay sp w ao ah n d er sp w ah sil y uw w sp aa r sil\n",
            "Phonemes indices: ['sil t w ih ng k ah sp t w ih ng k ah sp l ih t ow sp s t aa r sp hh aw sp ay sp w ah n d er sp w ah n sil y uw w sp aa r sil ah b sp ah b ah v sp dh ah sp w er ah d sp s ow sp hh ay sil l ay k sp ah sp d ay m eh n d sp ih n sp ah sp s k ay sil t w ih ng k ow sp t w ih ng k ah sp l ih t ow sp s t aa r sil hh aw sp ay sp w ao ah n d er sp w ah sil y uw w sp aa r sil w ah n sp ah sp b l ey z ih ng sp s aa n sp ih s sp g ao n sil w eh n sp hh iy sp n ah th ih ng sp sh ay n s sp ah p ao n sil dh eh n sp y ah sp sh ow sp y ao sp l ih t ow sp l ay t sil t w ah ng k ow sp t w ih ng k ow l sp ao sp dh ah sp n ay t sil t w ih ng k ah sp t w ih ng k ah sp l ih t ow sp s t aa r sil hh aw sp ay sp w ah n d er sp w ah sil y uw w sp aa r sil dh eh n sp ah sp ch r aa v l er sil ih n sp ah sp d aa r k sil th ey ng k s sp y uw sp f uw oy sp y ah r sp t ay n iy sp s p ao sil hh iy sp k uh sp n ao sp s iy sp w ih ch sp w ey sp t uw sp g ow sil ih f sp y uw sp d ih sp n aa sp t w ih n k ow sp s ow sil t w ih ng k ow sp t w ih ng k ah sp l ih t ow sp s dh ao r sil hh aw sp ay sp w ao ah n d er sp w ah sil y uw w sp aa r sil ih n sp ah sp d aa n sil b l uw sp s k ay sp y uw sp k iy p sp eh n d sil ao f eh n sp dh r uw sp m ay sp k ah er n s sp p iy p sil f ao ay sp y ah sp n eh v er sp sh ah sil y ao er sil ay sil t ah ao sp dh ah sp s aa n sp ih z sp ih n sp ah sp s k ay sil t w ih ng k ah sp t w ih ng k ow sp l ih t ow sp s t aa r sil hh aw sp ay sp w ao ah n d er sp w ah sil y uw w sp aa r sil ae s sp y uh er sp b r ay t sp eh n sp t ay n iy sp s p aa r k sil l ay s sp dh ah sp ch r ah v l ah r sp ih n sp ah sp d aa r k sil dh aw w sp ay sp n ow sp n aa t sp w ah sil y uw w sp aa r sil t w ih ng k ah sp t w ih ng k ow sp l ih t ow sp s t aa r sil t w ih ng k ah l sp t w ih ng k ah sp l ih t ow sp s t aa r sil hh aw sp ay sp w ao ah n d er sp w ah sp y uw w sp aa r sil ah p sp ah b ah f sp dh ah sp w er ah sp s ow sp hh ay sil l ay k sp ah sp d ay m ah n d sp ih n sp ah sp s k ay sil t w ih ng k ow sp t w ih ng k ah sp l ih t ow sp s t ao r sil hh aw sp ay sp w ah n d er sp w ao ah sil y uw w sp aa r sil hh aw sp ay sp w ao ah n d er sp w ah sil y uw w sp aa r sil']\n",
            "Mel Spec indices: tensor([[[-36.7630, -35.1728, -40.4450,  ..., -39.6069, -40.0712, -40.8777],\n",
            "         [-40.6233, -41.2652, -45.6434,  ..., -47.9595, -45.8319, -43.2562],\n",
            "         [-47.7150, -47.8752, -46.9433,  ..., -46.0630, -45.7762, -45.0564],\n",
            "         ...,\n",
            "         [-52.8002, -52.8002, -52.8002,  ..., -52.8002, -52.8002, -52.8002],\n",
            "         [-52.8002, -52.8002, -52.8002,  ..., -52.8002, -52.8002, -52.8002],\n",
            "         [-52.8002, -52.8002, -52.8002,  ..., -52.8002, -52.8002, -52.8002]]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/48 [02:04<1:37:17, 124.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sil l ih s ah n sp t uw sp v ah sp r ih dh ah m sp ao f sp dh ah sp f ao l ih ng sp r ey n sil t eh l iy ng sp m iy sp jh ah s w sp ah t sp ah sp f uw l sp ay f sp b ih n sil ay sp w ih sh sp jh ah t sp ih sp w uw sp g ow sp eh n sp l eh sp m iy sp k r ay sp ih n sp v ey n sil eh n sp l eh sp m iy sp b iy sp ah l ow n sp ah g ey n sil v iy y sp ow n l iy sp g ah l sp ay sp k eh r sp ah b aw t sp hh ah z sp g ao n sp ow w ey sil l uw k ih n sp f ao r sp ah sp b r eh n sp n iy uw sp s t aa r sil b ah sp l ih ow sp dh ah sp sh iy sp n ow sp dh eh sp w eh n sp sh iy sp l ae f sp dh eh sp d ey sil ah l ao ng sp w ih f sp hh ah r sp sh iy sp t uw k sp m ay sp hh aa r sil r ey n sp p iy s sp t ah sp m iy sp n ow sp d ah s sp dh ah sp t iy m sp f eh sil f ao sp hh ah sp t ah sp s t iy uw sp m ay sp hh aa r t sp ow w ey sp w ey n sp sh iy sp d ow n sp k eh sil ay sp k eh n sp l ah v sp ah n ah v ah sp w eh n sp m ay sp hh aa sp s ow m w eh ah sp f aa r ah w ey sil v iy y sp ow l iy sp g ah l sp ay sp k eh r sp ah b aw t sp hh eh s sp g ao n sp ow w ey sil l ow k ih n sp f ao r sp ah sp b r eh n sp n iy uw sp s t aa r t sil b ah sp l ih ow sp dh ah sp sh iy sp n ow sp dh eh t sp w eh n sp sh iy sp l eh f sp dh eh sp d ey sil ah l ao ow ng sp w ih f sp hh ah sp sh iy sp t uw k sp m ay sp hh aa r sil r ey n sp w ow ah n sp y uw sp t ow sp hh ah sp v eh sp aa sp l ah f sp hh ah sp s ow sil p l iy s sp ah s sp th ah sp s aa n sp uh sp s eh t sp hh ah r sp hh aa r t sp ah g l ow sil r ey n sp ih n sp hh ah sp hh aa t sp eh n sp l eh sp v ah sp l ah f sp w iy sp n iy uw sp s t aa sp t uw sp g r ow sil sil l ih s ah n sp t uw sp v ah sp r ih dh ah m sp ao f sp dh ah sp f ao l ih ng sp r ey n sil t eh l iy ng sp m iy sp jh ah s w sp ah t sp ah sp f uw l sp ay f sp b ih n sil ay sp w ih sh sp jh ah t sp ih sp w uw sp g ow sp eh n sp l eh sp m iy sp k r ay sp ih n sp v ey n sil eh n sp l eh sp m iy sp b iy sp ah l ow n sp ah g ey n sil v iy y sp ow n l iy sp g ah l sp ay sp k eh r sp ah b aw t sp hh ah z sp g ao n sp ow w ey sil l uw k ih n sp f ao r sp ah sp b r eh n sp n iy uw sp s t aa r sil b ah sp l ih ow sp dh ah sp sh iy sp n ow sp dh eh sp w eh n sp sh iy sp l ae f sp dh eh sp d ey sil ah l ao ng sp w ih f sp hh ah r sp sh iy sp t uw k sp m ay sp hh aa r sil r ey n sp p iy s sp t ah sp m iy sp n ow sp d ah s sp dh ah sp t iy m sp f eh sil f ao sp hh ah sp t ah sp s t iy uw sp m ay sp hh aa r t sp ow w ey sp w ey n sp sh iy sp d ow n sp k eh sil ay sp k eh n sp l ah v sp ah n ah v ah sp w eh n sp m ay sp hh aa sp s ow m w eh ah sp f aa r ah w ey sil v iy y sp ow l iy sp g ah l sp ay sp k eh r sp ah b aw t sp hh eh s sp g ao n sp ow w ey sil l ow k ih n sp f ao r sp ah sp b r eh n sp n iy uw sp s t aa r t sil b ah sp l ih ow sp dh ah sp sh iy sp n ow sp dh eh t sp w eh n sp sh iy sp l eh f sp dh eh sp d ey sil ah l ao ow ng sp w ih f sp hh ah sp sh iy sp t uw k sp m ay sp hh aa r sil r ey n sp w ow ah n sp y uw sp t ow sp hh ah sp v eh sp aa sp l ah f sp hh ah sp s ow sil p l iy s sp ah s sp th ah sp s aa n sp uh sp s eh t sp hh ah r sp hh aa r t sp ah g l ow sil r ey n sp ih n sp hh ah sp hh aa t sp eh n sp l eh sp v ah sp l ah f sp w iy sp n iy uw sp s t aa sp t uw sp g r ow sil\n",
            "Phonemes indices: ['sil l ih s ah n sp t uw sp v ah sp r ih dh ah m sp ao f sp dh ah sp f ao l ih ng sp r ey n sil t eh l iy ng sp m iy sp jh ah s w sp ah t sp ah sp f uw l sp ay f sp b ih n sil ay sp w ih sh sp jh ah t sp ih sp w uw sp g ow sp eh n sp l eh sp m iy sp k r ay sp ih n sp v ey n sil eh n sp l eh sp m iy sp b iy sp ah l ow n sp ah g ey n sil v iy y sp ow n l iy sp g ah l sp ay sp k eh r sp ah b aw t sp hh ah z sp g ao n sp ow w ey sil l uw k ih n sp f ao r sp ah sp b r eh n sp n iy uw sp s t aa r sil b ah sp l ih ow sp dh ah sp sh iy sp n ow sp dh eh sp w eh n sp sh iy sp l ae f sp dh eh sp d ey sil ah l ao ng sp w ih f sp hh ah r sp sh iy sp t uw k sp m ay sp hh aa r sil r ey n sp p iy s sp t ah sp m iy sp n ow sp d ah s sp dh ah sp t iy m sp f eh sil f ao sp hh ah sp t ah sp s t iy uw sp m ay sp hh aa r t sp ow w ey sp w ey n sp sh iy sp d ow n sp k eh sil ay sp k eh n sp l ah v sp ah n ah v ah sp w eh n sp m ay sp hh aa sp s ow m w eh ah sp f aa r ah w ey sil v iy y sp ow l iy sp g ah l sp ay sp k eh r sp ah b aw t sp hh eh s sp g ao n sp ow w ey sil l ow k ih n sp f ao r sp ah sp b r eh n sp n iy uw sp s t aa r t sil b ah sp l ih ow sp dh ah sp sh iy sp n ow sp dh eh t sp w eh n sp sh iy sp l eh f sp dh eh sp d ey sil ah l ao ow ng sp w ih f sp hh ah sp sh iy sp t uw k sp m ay sp hh aa r sil r ey n sp w ow ah n sp y uw sp t ow sp hh ah sp v eh sp aa sp l ah f sp hh ah sp s ow sil p l iy s sp ah s sp th ah sp s aa n sp uh sp s eh t sp hh ah r sp hh aa r t sp ah g l ow sil r ey n sp ih n sp hh ah sp hh aa t sp eh n sp l eh sp v ah sp l ah f sp w iy sp n iy uw sp s t aa sp t uw sp g r ow sil']\n",
            "Mel Spec indices: tensor([[[-41.3987, -40.6614, -39.4684,  ..., -39.2798, -35.7402, -39.8448],\n",
            "         [-42.8510, -39.8694, -41.3018,  ..., -47.2022, -43.5450, -42.0432],\n",
            "         [-44.1122, -40.8372, -43.3945,  ..., -51.4763, -50.3331, -49.0449],\n",
            "         ...,\n",
            "         [-54.9807, -54.9807, -54.9807,  ..., -54.9807, -54.9807, -54.9807],\n",
            "         [-54.9807, -54.9807, -54.9807,  ..., -54.9807, -54.9807, -54.9807],\n",
            "         [-54.9807, -54.9807, -54.9807,  ..., -54.9807, -54.9807, -54.9807]]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/48 [03:13<1:10:19, 91.73s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sil s sp l ey t sp iy n iy sp f n iy ng sil sh ih s sp w ah n jh r ih ng sp w ah t sp k l ow s sp t uh uw sp w eh er sil sh ih sp p uw s sp ah n sp hh er sp m ey k ah p sil eh n sp b r eh sh ih s sp hh ah sp l ao ng sp b l ah n sp hh ey eh ah r sil hh eh n sp eh n sp sh iy sp eh s sp m iy sil d uw w sp ay sp l ah uw k sp aa uh hh r ay t sil eh n sp ay sp s ey sp y eh s sil hh y uw sp l uw k sp hh w ah n d eh er f uw l sil t ih n ay t sil w ih sil k ah sp t uw w sp ah sp p aa r t ih sil eh n sp eh v r ih w ah n sp t ah r n s sp t uh sp s iy sil d ih s sp p ih uw t ih f uw sp l ey d iy sil d eh s sp w ao k ih n eh sp er r aw uw n sp w ih sil m iy sil hh eh n sp eh n sp sh iy sp eh s sp m iy sil t uw sp y uw sp f ih l sp ao r ay t sil eh n sp ay sp s ey sp y eh s sil ay sp f ih l ow sp hh w ah n d eh er f uw l sil t ah n ay sil ay sp f ih ow sp hh w ah n eh er f uw l sil b ih k ah s sp ay sp s iy sil d ah sp l ah f sp l ay t sp ih n sp y ao er r sp ay s sil hh eh n sp d ow sp w ah n d eh r sil ao f sp ih t sp ao ah sil ih s sp dh eh t sp y uw sp ch ah s sp t ow n t sp r iy ah l ay s sil hh aw sp m ah ch sp ah sp l ah f sp y uw sil ih s sp t ay m sp t uw sp g ow sp hh ow m sp n aw sil eh n sp eh aw f sp k ah t sp ah n sp hh ey k ih ng sp hh eh sil s ow w sp ay sp g iy ow f sp hh er sp d ih uw sp k aa r sp k iy s sil eh n sp sh ih sp hh eh ow s sp m iy sp t uw sp p eh d sil hh eh n sp eh n sp ay sp t eh ah l sp hh ah er sil eh s sp ay sp t er n sp ah sp dh ah sp l ay t sil ay sp s ey sp m ay sp t ah l iy ng sil y uw sp w ah er sp w ah n dh ih ah er f uw l sil t ih n ay t sil hh ow ah sp m ay sp d ah r l iy ng sil hh y uw sp w ah er sp w ah n d ah er f uw l sil t ih n ay t sil sil s sp l ey t sp iy n iy sp f n iy ng sil sh ih s sp w ah n jh r ih ng sp w ah t sp k l ow s sp t uh uw sp w eh er sil sh ih sp p uw s sp ah n sp hh er sp m ey k ah p sil eh n sp b r eh sh ih s sp hh ah sp l ao ng sp b l ah n sp hh ey eh ah r sil hh eh n sp eh n sp sh iy sp eh s sp m iy sil d uw w sp ay sp l ah uw k sp aa uh hh r ay t sil eh n sp ay sp s ey sp y eh s sil hh y uw sp l uw k sp hh w ah n d eh er f uw l sil t ih n ay t sil w ih sil k ah sp t uw w sp ah sp p aa r t ih sil eh n sp eh v r ih w ah n sp t ah r n s sp t uh sp s iy sil d ih s sp p ih uw t ih f uw sp l ey d iy sil d eh s sp w ao k ih n eh sp er r aw uw n sp w ih sil m iy sil hh eh n sp eh n sp sh iy sp eh s sp m iy sil t uw sp y uw sp f ih l sp ao r ay t sil eh n sp ay sp s ey sp y eh s sil ay sp f ih l ow sp hh w ah n d eh er f uw l sil t ah n ay sil ay sp f ih ow sp hh w ah n eh er f uw l sil b ih k ah s sp ay sp s iy sil d ah sp l ah f sp l ay t sp ih n sp y ao er r sp ay s sil hh eh n sp d ow sp w ah n d eh r sil ao f sp ih t sp ao ah sil ih s sp dh eh t sp y uw sp ch ah s sp t ow n t sp r iy ah l ay s sil hh aw sp m ah ch sp ah sp l ah f sp y uw sil ih s sp t ay m sp t uw sp g ow sp hh ow m sp n aw sil eh n sp eh aw f sp k ah t sp ah n sp hh ey k ih ng sp hh eh sil s ow w sp ay sp g iy ow f sp hh er sp d ih uw sp k aa r sp k iy s sil eh n sp sh ih sp hh eh ow s sp m iy sp t uw sp p eh d sil hh eh n sp eh n sp ay sp t eh ah l sp hh ah er sil eh s sp ay sp t er n sp ah sp dh ah sp l ay t sil ay sp s ey sp m ay sp t ah l iy ng sil y uw sp w ah er sp w ah n dh ih ah er f uw l sil t ih n ay t sil hh ow ah sp m ay sp d ah r l iy ng sil hh y uw sp w ah er sp w ah n d ah er f uw l sil t ih n ay t sil\n",
            "Phonemes indices: ['sil s sp l ey t sp iy n iy sp f n iy ng sil sh ih s sp w ah n jh r ih ng sp w ah t sp k l ow s sp t uh uw sp w eh er sil sh ih sp p uw s sp ah n sp hh er sp m ey k ah p sil eh n sp b r eh sh ih s sp hh ah sp l ao ng sp b l ah n sp hh ey eh ah r sil hh eh n sp eh n sp sh iy sp eh s sp m iy sil d uw w sp ay sp l ah uw k sp aa uh hh r ay t sil eh n sp ay sp s ey sp y eh s sil hh y uw sp l uw k sp hh w ah n d eh er f uw l sil t ih n ay t sil w ih sil k ah sp t uw w sp ah sp p aa r t ih sil eh n sp eh v r ih w ah n sp t ah r n s sp t uh sp s iy sil d ih s sp p ih uw t ih f uw sp l ey d iy sil d eh s sp w ao k ih n eh sp er r aw uw n sp w ih sil m iy sil hh eh n sp eh n sp sh iy sp eh s sp m iy sil t uw sp y uw sp f ih l sp ao r ay t sil eh n sp ay sp s ey sp y eh s sil ay sp f ih l ow sp hh w ah n d eh er f uw l sil t ah n ay sil ay sp f ih ow sp hh w ah n eh er f uw l sil b ih k ah s sp ay sp s iy sil d ah sp l ah f sp l ay t sp ih n sp y ao er r sp ay s sil hh eh n sp d ow sp w ah n d eh r sil ao f sp ih t sp ao ah sil ih s sp dh eh t sp y uw sp ch ah s sp t ow n t sp r iy ah l ay s sil hh aw sp m ah ch sp ah sp l ah f sp y uw sil ih s sp t ay m sp t uw sp g ow sp hh ow m sp n aw sil eh n sp eh aw f sp k ah t sp ah n sp hh ey k ih ng sp hh eh sil s ow w sp ay sp g iy ow f sp hh er sp d ih uw sp k aa r sp k iy s sil eh n sp sh ih sp hh eh ow s sp m iy sp t uw sp p eh d sil hh eh n sp eh n sp ay sp t eh ah l sp hh ah er sil eh s sp ay sp t er n sp ah sp dh ah sp l ay t sil ay sp s ey sp m ay sp t ah l iy ng sil y uw sp w ah er sp w ah n dh ih ah er f uw l sil t ih n ay t sil hh ow ah sp m ay sp d ah r l iy ng sil hh y uw sp w ah er sp w ah n d ah er f uw l sil t ih n ay t sil']\n",
            "Mel Spec indices: tensor([[[-35.3316, -35.9088, -38.0888,  ..., -18.8680, -19.5793, -20.7186],\n",
            "         [-37.0315, -36.2068, -39.2543,  ..., -36.5887, -40.1004, -39.6761],\n",
            "         [-46.0537, -42.8950, -41.7573,  ..., -42.0787, -40.6676, -41.1448],\n",
            "         ...,\n",
            "         [-52.8478, -52.8478, -52.8478,  ..., -52.8478, -52.8478, -52.8478],\n",
            "         [-52.8478, -52.8478, -52.8478,  ..., -52.8478, -52.8478, -52.8478],\n",
            "         [-52.8478, -52.8478, -52.8478,  ..., -52.8478, -52.8478, -52.8478]]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 3/48 [04:26<1:02:25, 83.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sil hh ih s sp l ey t sp ih n sp dh ah sp iy ih f n ih ng sil sh ih s sp w ao ah n d r ih ng sp w ah sp k l ow s sp t uw sp w eh sil sh iy sp p uh s sp ao n sp hh er sp m ey k ah sil hh eh m sp b r ah sh ah s sp hh ah sp l ao ng sp b l ao n sp hh eh er sil hh eh n sp dh eh n sp sh iy y sp ae s sp m iy sil n d y uw w sp ay sp l uh k sp ah ow uw r ay t sil hh eh n sp ay sp s ey sp y eh s sil y uw sp l uh k sp w ao n d er f ow l sp t ah n ay sil w iy sp g ow sp t uw w sp ah sp p aa r t iy sil hh eh n sp eh v r iy w ah n sp t ah n s sp t uw sp s iy sil d ih s sp p y uw t ih f uw sp l ey d iy sil n d eh s sp w ao k iy ih ng sp ah er r aw n sp w ih s sp m iy sil hh eh n sp d eh n sp sh iy y sp eh s sp m iy sil d uw sp y uh sp f iy ih l sp ao r ay sil eh n sp ay sp s ey sp y eh s sil hh ay sp f ih ah ow sp v w ah n d ah f ow l sp t ah n ay sil ay sp f ih ah ow sp v w ao ah n d ah f ow l sil b iy k ah z sp ay sp s iy sp d ah sp l ah v sp l ay t sil hh ih n sp y ao r sp ay s sil eh n sp d ah sp w ao ah n d er r sp ao f sil ih t sp ao l sil ih z sp ae ch sp y uw sp jh ah s sp d ow n sp r ih ah l ay s sil hh aw sp m ah ch sp ay sp l ah f sp y uw sil hh ih s sp t ay m sp t uw sp g ow sp hh ow m sp n aw sil hh eh n sp aa f sp g aa t sp eh n sp ey k iy ng sp hh eh sil s ow w sp ay sp k iy f sp hh ah sp dh ah sp k aa sp k iy s sil hh eh n sp sh iy sp hh eh aw s sp m iy sp t uw sp p eh t sil eh n sp d eh n sp ay sp s eh ah l sp hh ah er sil eh z sp ay sp t ah n sp aw sp d ah sp l ay t sil ay sp s ey sp m ay sp d aa l ey ng sil y uw sp w ah sp w ah n d ah f ow l sp t ah n ay sil ow sp m ay sp d aa l ey ng sil y w sp w ah sp w ah n d ah f ow l sp t ah n ay sil sil hh ih s sp l ey t sp ih n sp dh ah sp iy ih f n ih ng sil sh ih s sp w ao ah n d r ih ng sp w ah sp k l ow s sp t uw sp w eh sil sh iy sp p uh s sp ao n sp hh er sp m ey k ah sil hh eh m sp b r ah sh ah s sp hh ah sp l ao ng sp b l ao n sp hh eh er sil hh eh n sp dh eh n sp sh iy y sp ae s sp m iy sil n d y uw w sp ay sp l uh k sp ah ow uw r ay t sil hh eh n sp ay sp s ey sp y eh s sil y uw sp l uh k sp w ao n d er f ow l sp t ah n ay sil w iy sp g ow sp t uw w sp ah sp p aa r t iy sil hh eh n sp eh v r iy w ah n sp t ah n s sp t uw sp s iy sil d ih s sp p y uw t ih f uw sp l ey d iy sil n d eh s sp w ao k iy ih ng sp ah er r aw n sp w ih s sp m iy sil hh eh n sp d eh n sp sh iy y sp eh s sp m iy sil d uw sp y uh sp f iy ih l sp ao r ay sil eh n sp ay sp s ey sp y eh s sil hh ay sp f ih ah ow sp v w ah n d ah f ow l sp t ah n ay sil ay sp f ih ah ow sp v w ao ah n d ah f ow l sil b iy k ah z sp ay sp s iy sp d ah sp l ah v sp l ay t sil hh ih n sp y ao r sp ay s sil eh n sp d ah sp w ao ah n d er r sp ao f sil ih t sp ao l sil ih z sp ae ch sp y uw sp jh ah s sp d ow n sp r ih ah l ay s sil hh aw sp m ah ch sp ay sp l ah f sp y uw sil hh ih s sp t ay m sp t uw sp g ow sp hh ow m sp n aw sil hh eh n sp aa f sp g aa t sp eh n sp ey k iy ng sp hh eh sil s ow w sp ay sp k iy f sp hh ah sp dh ah sp k aa sp k iy s sil hh eh n sp sh iy sp hh eh aw s sp m iy sp t uw sp p eh t sil eh n sp d eh n sp ay sp s eh ah l sp hh ah er sil eh z sp ay sp t ah n sp aw sp d ah sp l ay t sil ay sp s ey sp m ay sp d aa l ey ng sil y uw sp w ah sp w ah n d ah f ow l sp t ah n ay sil ow sp m ay sp d aa l ey ng sil y w sp w ah sp w ah n d ah f ow l sp t ah n ay sil\n",
            "Phonemes indices: ['sil hh ih s sp l ey t sp ih n sp dh ah sp iy ih f n ih ng sil sh ih s sp w ao ah n d r ih ng sp w ah sp k l ow s sp t uw sp w eh sil sh iy sp p uh s sp ao n sp hh er sp m ey k ah sil hh eh m sp b r ah sh ah s sp hh ah sp l ao ng sp b l ao n sp hh eh er sil hh eh n sp dh eh n sp sh iy y sp ae s sp m iy sil n d y uw w sp ay sp l uh k sp ah ow uw r ay t sil hh eh n sp ay sp s ey sp y eh s sil y uw sp l uh k sp w ao n d er f ow l sp t ah n ay sil w iy sp g ow sp t uw w sp ah sp p aa r t iy sil hh eh n sp eh v r iy w ah n sp t ah n s sp t uw sp s iy sil d ih s sp p y uw t ih f uw sp l ey d iy sil n d eh s sp w ao k iy ih ng sp ah er r aw n sp w ih s sp m iy sil hh eh n sp d eh n sp sh iy y sp eh s sp m iy sil d uw sp y uh sp f iy ih l sp ao r ay sil eh n sp ay sp s ey sp y eh s sil hh ay sp f ih ah ow sp v w ah n d ah f ow l sp t ah n ay sil ay sp f ih ah ow sp v w ao ah n d ah f ow l sil b iy k ah z sp ay sp s iy sp d ah sp l ah v sp l ay t sil hh ih n sp y ao r sp ay s sil eh n sp d ah sp w ao ah n d er r sp ao f sil ih t sp ao l sil ih z sp ae ch sp y uw sp jh ah s sp d ow n sp r ih ah l ay s sil hh aw sp m ah ch sp ay sp l ah f sp y uw sil hh ih s sp t ay m sp t uw sp g ow sp hh ow m sp n aw sil hh eh n sp aa f sp g aa t sp eh n sp ey k iy ng sp hh eh sil s ow w sp ay sp k iy f sp hh ah sp dh ah sp k aa sp k iy s sil hh eh n sp sh iy sp hh eh aw s sp m iy sp t uw sp p eh t sil eh n sp d eh n sp ay sp s eh ah l sp hh ah er sil eh z sp ay sp t ah n sp aw sp d ah sp l ay t sil ay sp s ey sp m ay sp d aa l ey ng sil y uw sp w ah sp w ah n d ah f ow l sp t ah n ay sil ow sp m ay sp d aa l ey ng sil y w sp w ah sp w ah n d ah f ow l sp t ah n ay sil']\n",
            "Mel Spec indices: tensor([[[-46.7228, -42.6949, -43.8546,  ..., -43.8953, -31.2438, -26.7931],\n",
            "         [-52.3679, -44.7512, -44.7012,  ..., -45.4817, -25.2202, -21.1394],\n",
            "         [-57.9841, -51.6504, -49.1289,  ..., -40.5839, -19.7983, -16.6176],\n",
            "         ...,\n",
            "         [-59.1294, -59.1294, -59.1294,  ..., -59.1294, -59.1294, -55.4811],\n",
            "         [-59.1294, -59.1294, -59.1294,  ..., -59.1294, -59.1294, -55.1103],\n",
            "         [-59.1294, -59.1294, -59.1294,  ..., -59.1294, -59.1294, -55.7576]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tacotron_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ4z7EGJVHpj",
        "outputId": "516b8aed-a0f8-4887-940e-bda51f391466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TacotronWrapper(\n",
            "  (text_to_melody): MBartForConditionalGeneration(\n",
            "    (model): MBartModel(\n",
            "      (shared): MBartScaledWordEmbedding(250027, 1024, padding_idx=1)\n",
            "      (encoder): MBartEncoder(\n",
            "        (embed_tokens): MBartScaledWordEmbedding(250027, 1024, padding_idx=1)\n",
            "        (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
            "        (layers): ModuleList(\n",
            "          (0-11): 12 x MBartEncoderLayer(\n",
            "            (self_attn): MBartSdpaAttention(\n",
            "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (activation_fn): GELUActivation()\n",
            "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (decoder): MBartDecoder(\n",
            "        (embed_tokens): MBartScaledWordEmbedding(250027, 1024, padding_idx=1)\n",
            "        (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
            "        (layers): ModuleList(\n",
            "          (0-11): 12 x MBartDecoderLayer(\n",
            "            (self_attn): MBartSdpaAttention(\n",
            "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            )\n",
            "            (activation_fn): GELUActivation()\n",
            "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (encoder_attn): MBartSdpaAttention(\n",
            "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            )\n",
            "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (lm_head): Linear(in_features=1024, out_features=250027, bias=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for phonemes, mel_spec in dataloader:\n",
        "    print(\"Mel Spec Shape:\", mel_spec.shape)\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWAbyAgg5eUF",
        "outputId": "25492318-5407-4eaf-c126-78cd2e48ff45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mel Spec Shape: torch.Size([1, 80, 7218])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tacotron_model.eval()\n",
        "for phonemes, mel_spec in dataloader:\n",
        "    with torch.no_grad():\n",
        "        generated_mel = tacotron_model(phonemes)\n",
        "        print(\"Generated Mel Shape:\", generated_mel.shape)\n",
        "        break\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_FmlJS85jDp",
        "outputId": "628d41c9-5aa5-4df4-d0f4-fbdae7676231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Mel Shape: torch.Size([1, 869, 250027])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NZnrHMChx8so"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}