{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":57712,"sourceType":"datasetVersion","datasetId":37892}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torch transformers pytorch-lightning datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:52:18.241560Z","iopub.execute_input":"2024-12-04T11:52:18.242107Z","iopub.status.idle":"2024-12-04T11:52:27.865475Z","shell.execute_reply.started":"2024-12-04T11:52:18.242077Z","shell.execute_reply":"2024-12-04T11:52:27.864672Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\nRequirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.6.0)\nRequirement already satisfied: lightning-utilities>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (0.11.9)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (70.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport transformers\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom datasets import load_dataset\nimport pytorch_lightning as pl\nfrom typing import Optional, Dict\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T13:39:51.333824Z","iopub.execute_input":"2024-12-04T13:39:51.334809Z","iopub.status.idle":"2024-12-04T13:39:59.256012Z","shell.execute_reply.started":"2024-12-04T13:39:51.334758Z","shell.execute_reply":"2024-12-04T13:39:59.255256Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nimport pytorch_lightning as pl\nfrom datasets import Dataset\nfrom transformers import (\n    AutoModelForSeq2SeqLM, \n    AutoTokenizer, \n    DataCollatorForSeq2Seq\n)\nfrom torch.utils.data import DataLoader\nfrom pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T15:17:00.051232Z","iopub.execute_input":"2024-12-04T15:17:00.051615Z","iopub.status.idle":"2024-12-04T15:17:00.056405Z","shell.execute_reply.started":"2024-12-04T15:17:00.051586Z","shell.execute_reply":"2024-12-04T15:17:00.055494Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"class TaylorSwiftLineCompletionModel(pl.LightningModule):\n    def __init__(self, model_name: str, learning_rate: float, max_length: int):\n        super().__init__()\n        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.learning_rate = learning_rate\n        self.max_length = max_length\n        self.save_hyperparameters()\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        return self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n\n    def training_step(self, batch, batch_idx):\n        outputs = self.model(\n            input_ids=batch[\"input_ids\"],\n            attention_mask=batch[\"attention_mask\"],\n            labels=batch[\"labels\"]\n        )\n        loss = outputs.loss\n        self.log(\"train_loss\", loss, prog_bar=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        outputs = self.model(\n            input_ids=batch[\"input_ids\"],\n            attention_mask=batch[\"attention_mask\"],\n            labels=batch[\"labels\"]\n        )\n        loss = outputs.loss\n        self.log(\"val_loss\", loss, prog_bar=True)\n        return loss\n\n    def configure_optimizers(self):\n        return torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n\n    def generate_line_completion(self, prompt: str):\n        inputs = self.tokenizer(\n            prompt, \n            return_tensors=\"pt\", \n            truncation=True, \n            max_length=self.max_length\n        ).to(self.device)\n        \n        outputs = self.model.generate(\n            input_ids=inputs[\"input_ids\"], \n            attention_mask=inputs[\"attention_mask\"], \n            max_length=self.max_length, \n            num_beams=3, \n            early_stopping=True\n        )\n        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T15:15:16.458158Z","iopub.execute_input":"2024-12-04T15:15:16.458824Z","iopub.status.idle":"2024-12-04T15:15:16.468019Z","shell.execute_reply.started":"2024-12-04T15:15:16.458776Z","shell.execute_reply":"2024-12-04T15:15:16.467110Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"def prepare_taylor_swift_dataset(csv_path: str):\n    df = pd.read_csv(csv_path, encoding='ISO-8859-1')\n    \n    if 'lyric' in df.columns:\n        df = df.rename(columns={\"lyric\": \"lyrics\"})\n    \n    df = df.dropna(subset=['lyrics'])\n    \n    tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n    \n    special_tokens = [\"<line>\", \"</line>\"]\n    tokenizer.add_special_tokens({'additional_special_tokens': special_tokens})\n\n    def tokenize_function(examples):\n        input_texts = []\n        target_texts = []\n        \n        for i in range(len(examples['lyrics']) - 1):\n            input_texts.append(f\"<line> {examples['lyrics'][i]} </line>\")\n            target_texts.append(f\"<line> {examples['lyrics'][i+1]} </line>\")\n        \n        inputs = tokenizer(input_texts, \n                           max_length=256, \n                           truncation=True, \n                           padding=True)\n        targets = tokenizer(target_texts, \n                            max_length=256, \n                            truncation=True, \n                            padding=True)\n        \n        inputs[\"labels\"] = targets[\"input_ids\"]\n        return inputs\n\n    dataset = Dataset.from_pandas(df[['lyrics']])\n    dataset = dataset.map(tokenize_function, \n                          batched=True, \n                          remove_columns=['lyrics'])\n    \n    dataset = dataset.train_test_split(test_size=0.1)\n    \n    return dataset, tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T15:15:33.126942Z","iopub.execute_input":"2024-12-04T15:15:33.127293Z","iopub.status.idle":"2024-12-04T15:15:33.134638Z","shell.execute_reply.started":"2024-12-04T15:15:33.127248Z","shell.execute_reply":"2024-12-04T15:15:33.133675Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"def train_taylor_swift_line_completion_model(csv_path: str, save_dir: str = \"model_checkpoints\"):\n    pl.seed_everything(42)\n    \n    # Ensure save directory exists\n    os.makedirs(save_dir, exist_ok=True)\n    \n    dataset, tokenizer = prepare_taylor_swift_dataset(csv_path)\n    \n    data_collator = DataCollatorForSeq2Seq(\n        tokenizer=tokenizer, \n        model=\"facebook/bart-base\"\n    )\n    \n    train_loader = DataLoader(\n        dataset[\"train\"], \n        batch_size=4, \n        shuffle=True, \n        collate_fn=data_collator\n    )\n    val_loader = DataLoader(\n        dataset[\"test\"], \n        batch_size=4, \n        collate_fn=data_collator\n    )\n    \n    # Configure model checkpointing\n    checkpoint_callback = ModelCheckpoint(\n        dirpath=save_dir,\n        filename='taylor_swift_model-{epoch:02d}-{val_loss:.2f}',\n        save_top_k=3,\n        verbose=True,\n        monitor='val_loss',\n        mode='min'\n    )\n    \n    lr_monitor = LearningRateMonitor(logging_interval='epoch')\n    \n    # Initialize model\n    model = TaylorSwiftLineCompletionModel(\n        model_name=\"facebook/bart-base\",\n        learning_rate=2e-4,\n        max_length=256\n    )\n    \n    model.model.resize_token_embeddings(len(tokenizer))\n    \n    # Configure trainer with verbose output\n    trainer = pl.Trainer(\n        max_epochs=5,\n        devices=1,\n        accelerator=\"gpu\",\n        precision=32,\n        accumulate_grad_batches=2,\n        gradient_clip_val=0.5,\n        val_check_interval=0.25,\n        callbacks=[checkpoint_callback, lr_monitor],\n        enable_model_summary=True,\n        log_every_n_steps=10\n    )\n    \n    # Train model\n    trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n    \n    # Save final model and tokenizer\n    final_save_path = os.path.join(save_dir, \"final_model\")\n    model.model.save_pretrained(final_save_path)\n    tokenizer.save_pretrained(final_save_path)\n    \n    return model, tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T15:17:45.309228Z","iopub.execute_input":"2024-12-04T15:17:45.309643Z","iopub.status.idle":"2024-12-04T15:17:45.318385Z","shell.execute_reply.started":"2024-12-04T15:17:45.309609Z","shell.execute_reply":"2024-12-04T15:17:45.317334Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"    csv_path = \"/kaggle/input/taylor-swift-song-lyrics-from-all-the-albums/taylor_swift_lyrics.csv\"\n    trained_model, tokenizer = train_taylor_swift_line_completion_model(csv_path)\n    \n    prompts = [\n        \"I remember when we broke up the first time\",\n        \"Saying goodbye is death by a thousand cuts\",\n        \"And I can go anywhere I want\"\n    ]\n    \n    print(\"Generated Line Completions:\")\n    for prompt in prompts:\n        completion = trained_model.generate_line_completion(prompt)\n        print(f\"Prompt: {prompt}\")\n        print(f\"Completion: {completion}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T15:17:47.033111Z","iopub.execute_input":"2024-12-04T15:17:47.033502Z","iopub.status.idle":"2024-12-04T15:28:34.042125Z","shell.execute_reply.started":"2024-12-04T15:17:47.033469Z","shell.execute_reply":"2024-12-04T15:28:34.041056Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4862 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc5a5742f49b4c588bfaac6175c18d4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e96bbe72d4544a05b2a224cb3444e874"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3770651f640c406cafdba2aac70c6f1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bf801f8746b465199d133cb3dcc422d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32307b0cc7594dff947410b65a848ba5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2a0984bfada4ea1af246b2c39bbc60d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e6153e52d294cb9a1f936ac70f6b6f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60ba628ff3a3468b8109c78570629f31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dfef637dfe3499a83371e1ab641ac42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d50d4a74257342c38c6a6e239e653ca1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0d10baf781a44afb299b6bdca4a71fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32f23b63f3a64e3d9bfefc7c4f5d0a22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7375e3c4d60c40abbf1b6798eb1e682f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d8d9cd319c54c118077f9fa208fadd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd8b6d94ad0546798396f9679905779c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00d41235beaf45128cda94d5b2419f8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"820032ef50d04520b7b2e636527ec293"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2408eb7b90a4eec96b6a0038137ee2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a4100ac67f94405b9372a9aedd45198"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d09896bcea994bb2987283ca7ada0d2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ed83deec1a940c8ac4b8bb8f715f363"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f45d302c24af4cef9ce1c967330bb457"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce9b60622e454d8d8fba9d70c175362c"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Generated Line Completions:\nPrompt: I remember when we broke up the first time\nCompletion:  In the darkest little paradise \n\nPrompt: Saying goodbye is death by a thousand cuts\nCompletion:  All I know is that you held the door \n\nPrompt: And I can go anywhere I want\nCompletion:  Cause I'm not the kind of girl \n\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"import shutil\nimport os\nfrom IPython.display import FileLink\n\ndef download_folder(folder_path: str, output_filename: str):\n    # Create a zip archive of the folder\n    shutil.make_archive(output_filename, 'zip', folder_path)\n    \n    # Generate a download link\n    return FileLink(f\"{output_filename}.zip\")\n\n# Specify the folder path and output file name\nfolder_path = \"/kaggle/working/model_checkpoints/final_model\"  # Path to the folder you want to download\noutput_filename = \"english song model mbert\"  # Desired output file name (without extension)\n\n# Create the download link\ndownload_folder(folder_path, output_filename)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T15:37:51.979052Z","iopub.execute_input":"2024-12-04T15:37:51.979449Z","iopub.status.idle":"2024-12-04T15:38:23.620112Z","shell.execute_reply.started":"2024-12-04T15:37:51.979413Z","shell.execute_reply":"2024-12-04T15:38:23.619160Z"}},"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/english song model mbert.zip","text/html":"<a href='english song model mbert.zip' target='_blank'>english song model mbert.zip</a><br>"},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}